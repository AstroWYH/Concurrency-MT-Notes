在并发编程中，锁的数量取决于**共享资源的独立性和线程安全需求**。以下是何时使用单锁（如`queueMutex`）或双锁的详细分析及示例：

---

### **一、何时使用单锁（如`queueMutex`）？**
#### **1. 适用场景**
- **资源高度关联**：当多个共享资源（如任务队列和停止标志`stop`）在逻辑上紧密关联，且需要**原子性操作**时，单锁更简单高效。  
- **避免死锁风险**：单锁无需考虑多锁的获取顺序，降低复杂度。  

#### **2. 线程池示例分析**
```cpp
std::queue<Task> tasks;  // 任务队列
bool stop = false;       // 停止标志
std::mutex queueMutex;   // 单锁保护两者

void workerThread() {
    while (true) {
        std::unique_lock<std::mutex> lock(queueMutex);
        condition.wait(lock, [this] { return stop || !tasks.empty(); });
        if (stop) break;
        Task task = std::move(tasks.front());
        tasks.pop();
        lock.unlock();
        task.execute();
    }
}
```
**为什么用单锁？**  
- `stop`和`tasks`的修改和检查通常需要**同步**（如停止时清空队列）。  
- 条件变量`condition`的等待和唤醒依赖同一把锁，确保原子性。

#### **3. 单锁的局限性**
- **性能瓶颈**：若任务提交频繁且`stop`检查较少，单锁会导致不必要的竞争（如`stop`的读写被队列操作阻塞）。

---

### **二、何时需要两把锁？**
#### **1. 适用场景**
- **资源独立性**：两组数据无直接关联，且被不同线程频繁访问。  
- **读写分离**：读多写少的场景（如统计计数与任务队列分离）。  

#### **2. 典型示例**
##### **（1）独立资源保护**
```cpp
std::queue<Task> tasks;  // 任务队列
std::atomic<int> activeThreads; // 活跃线程计数
std::mutex taskMutex;    // 锁1：保护任务队列
std::mutex statsMutex;   // 锁2：保护统计计数

void workerThread() {
    {
        std::lock_guard<std::mutex> lock(statsMutex);
        activeThreads++;
    }
    while (true) {
        Task task;
        {
            std::unique_lock<std::mutex> lock(taskMutex);
            if (tasks.empty()) break;
            task = std::move(tasks.front());
            tasks.pop();
        }
        task.execute();
    }
}
```
**优势**：  
- `activeThreads`的修改无需阻塞任务队列操作，提高并发性。

##### **（2）生产者-消费者模型优化**
```cpp
std::queue<Task> highPriorityTasks;  // 高优先级队列
std::queue<Task> lowPriorityTasks;   // 低优先级队列
std::mutex highPriorityMutex;       // 锁1：高优先级队列
std::mutex lowPriorityMutex;        // 锁2：低优先级队列

void producer() {
    std::lock_guard<std::mutex> lock1(highPriorityMutex);
    highPriorityTasks.push(Task());
}

void consumer() {
    Task task;
    {
        std::lock_guard<std::mutex> lock1(highPriorityMutex);
        if (!highPriorityTasks.empty()) {
            task = highPriorityTasks.front();
            highPriorityTasks.pop();
        } else {
            std::lock_guard<std::mutex> lock2(lowPriorityMutex);
            task = lowPriorityTasks.front();
            lowPriorityTasks.pop();
        }
    }
    task.execute();
}
```
**优势**：  
- 双锁允许高/低优先级任务独立处理，减少竞争。

##### **（3）读写分离（`std::shared_mutex`）**
```cpp
std::vector<int> data;
std::shared_mutex dataMutex;  // 读写锁

// 读操作（多线程并发）
void readData() {
    std::shared_lock<std::shared_mutex> lock(dataMutex);
    // 读取data...
}

// 写操作（独占）
void writeData(int value) {
    std::unique_lock<std::shared_mutex> lock(dataMutex);
    data.push_back(value);
}
```
**优势**：  
- 读操作不阻塞其他读线程，大幅提升读多写少场景的性能。

---

### **三、选择单锁或双锁的核心原则**
| **场景**                | **锁策略**          | **理由**                                                                 |
|-------------------------|---------------------|--------------------------------------------------------------------------|
| 资源强关联（如`stop`和队列） | 单锁                | 确保原子性，避免状态不一致                                   |
| 独立资源（如队列与统计）    | 双锁                | 减少竞争，提升并发度                                         |
| 读多写少（如配置数据）      | 读写锁（`shared_mutex`） | 优化读性能                                                        |
| 多优先级任务              | 多锁（按优先级分组）  | 避免低优先级任务阻塞高优先级任务                              |

---

### **四、注意事项**
1. **死锁风险**：使用多锁时，必须全局约定**一致的加锁顺序**（如先锁A再锁B）。  
2. **性能权衡**：锁越多，并发性可能越高，但复杂度也越高。优先满足正确性，再优化性能。  
3. **替代方案**：考虑无锁数据结构（如`std::atomic`）或更高级抽象（如`std::async`）。

通过合理选择锁策略，可以平衡线程安全与性能需求。
